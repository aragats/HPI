\section{Introduction}


When researching in network security and security analytics areas, it is very important to have an appropriate testbed. The appropriate testbed includes appropriate data in needed amount and an appropriate test network environment. But often researchers do not have one of them or both of them.  

In case with data, the lack of data is a result of the fact that mostly the huge amount of data belongs to industrial companies, but they are usually not able to share them because of security and privacy reasons. The limitation with data makes data for security research is more inaccessible. And even if there is possibility to get such information, this information should be anonymized before exporting for analysis. Therefore, researchers have to simulate scenarios and generate data. And it means that we have new challenges, such as how to simulate a scenario, how to generate data, how to design a scenario based on modeling user behavior. 

In case with a test network environment, researchers need to create and configure a test network environment manually. Even if the installation is manual, it is still a challenge, because it is needed to set up a test network environment of enterprise or campus level. It means that we have to set up different complex systems, for instance, a domain controller. 

Any test network has its own specifics. In case with research in the area of network security and security analytics, this specifics means that often needed to have a potentially vulnerable environment and that means that old and vulnerable software applications must be installed. This restriction complicates the ability to use many existing IT automation systems, such as Chef\footnote{Chef. http://www.getchef.com} and Puppet\footnote{Puppet. http://puppetlabs.com}. %These problems are common to many researchers, but for researchers in the are of network security and security analytics, these issues become challenges. 

There are several ways to generate data. One of them is to generate synthetic data. This method implies that you know about the structure of data, the correlation between data and you roughly know what the result of analysis will be on the generated data. The advantage of this method is that you do not need to have a test network environment and you can generate any data if you know the structure of them. If the structure is quite simple then this way is more preferable. But if the structure of data and the correlation between data are very complex and varies then this approach becomes complicated, because in this case, you have to implement algorithms for each type of data and for each correlation. 

%And as a result, it makes an overhead of research work.

% and   But there is the disadvantage of this approach that makes the overhead of applying this approach. The disadvantage is that the structure of data can be very complex and varies and the correlation between data can be not clear. And it makes  The similar approach is used in testing of software applications and it is called assembly testing. 

Another approach to generate needed data is based on the simulation of some activities needed to produce this data [1]. This approach is more complex than the first one in case of simple data, because you need to set up a test network environment before applying the simulation. Despite the fact that this approach is more complex, it is more flexible and it can be applied for generation data with complex structure, because we do not need to care about the structure of data or the correlation between data. We need to care only about the simulation of specific activities. Also, this approach is suitable for real-time research, for example, for generating data for real-time intrusion detection systems. 

 
%TODO the related works

Within the IT security team of the chair "Internet Technologies and Systems" we also face with problems of the lack of testbeds. We are trying to solve them by automation the process of the testbed creation. In the second section of the report, I show how we solve the problem of the lack of data by the simulation of user behavior.



%The scientific world has some problems that slow down research progress. Some of them are obvious. One of them is the lack of data. Researchers need data for research. The huge amount of data belongs to industrial companies, but they do not hurry to share them because of security and privacy reasons. Researchers have to generate and simulate data. Further, many researchers need to create and configure a test network environment for research. It means that they have to run virtual machines, install software applications and configure the network. The third problem is that researchers need to simulate some activities on the test environment such as user behavior, opening connections, running services and so on. These problems are common to many researchers, but for researchers in the security analytic and network security areas, these issues become challenges. The data for security research is more inaccessible than others. For example, domain controller logs often contain personal information, e.g. user Id, time of login and logout events. This information is often an object of data privacy and should be anonymized before exporting for analysis. And it actually means that almost there is not a chance to get this data. The test environments for research in the security area are usually more specific. Every often it is needed to have a potentially vulnerable environment, and that means that old and vulnerable software applications must be installed. This restriction complicates the ability to use many existing IT automation systems such as Chef\footnote{Chef. http://www.getchef.com} and Puppet\footnote{Puppet. http://puppetlabs.com}. The remainder of the report covers ideas, ways of overcoming some mentioned issues and an overview of research projects.

%The remainder of the paper is structured as follow: 


%, because often researchers have to create testbeds manually. In the IT security group we also face with these problems